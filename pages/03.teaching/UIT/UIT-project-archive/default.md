---
title: UIT Project Archive
---
#UIT Project Archive

In this page Iâ€™ll keep the best projects developed by students of the 
UIT course. The projects may be used by students for understanding how 
a project should be designed, coded and presented.

Thank you very much to all the students that provided this material.


##Academic Year
* [2020-2021](#2020)
    * [LSTM for real-time stroke gestures recognition](#lstm)
* [2019-2020](#2019)
    * [FeedBucket](#feedbucket)
* [2018-2019](#2018)
    * [PAC-PAC](#pac-pac)
    * [AI4Fit](#ai4fit)
    * [MR2](#mr2)
      
<a id="2020"></a>   
##2020-2021

<a id="lstm"></a>
<hr>

###Applying Long-Short Term Memory Recurrent Neural Networks for Real-Time Stroke Recognition.
*Emanuele Ledda*

####Abstract
The project is about building a real-time recognizer for stroke gestures based on Long Short Term Memory Recurrent Neural Networks. The recognizer provides both the gesture class prediction and the completion percentage estimation for each point in the stroke while the user is performing it. It considers the stroke vocabulary of the $1 and $N datasets, defining four different architectures. The training used synthetic data, and we assessed the recognition accuracy on the original $1 and $N datasets. The results show an accuracy comparable with state of the art approaches classifying the stroke when completed, and a good precision in the completion percentage estimation.

####Paper 
The paper was accepted as a TechNote at the Engineering Interactive Computing System Conference ([EICS 2021](https://eics.acm.org/eics2021/))

[Fulltext](2020/eics2021_technote.pdf)

<a id="2019"></a>

##2019-2020

<a id="feedbucket"></a>
<hr>

###FeedBucket
*Valentino Artizzu, Davide Fara, Riccardo Macis*

####Abstract
The project introduces a simplified structure for the creation, 
assignment and execution of haptic feedback for standard controllers 
with the optional feature of synchronizing an haptic pattern to an 
auditory feedback. In addition, it reports the results of a preliminary 
test investigating the users' ability in recognizing variations in 
intensity and/or duration of the stimulus, especially when the two 
dimensions are combined for encoding information.

####Paper
The paper was accepted as a poster at the 2020 International Conference on 
Advanced Visual Interfaces ([AVI 2020](https://sites.google.com/unisa.it/avi2020/home))-

[Fulltext](2019/feedbucket-avi-v1.pdf)

<a id="2018"></a>

##2018-2019

<a id="pac-pac"></a>
<hr>

###PAC-PAC
*Filippo Andrea Fanni, Martina Senis, Alessandro Tola*

####Abstract
The project is about a tool for supporting end-users in the development of 
point-and-click videogames based on 360 degrees videos. It aims specifically at 
people without previous experience in game development and coding. 
Users can easily create scenes, add simple objects such as transitions or 
switches, connect scenes to each other and define the game rules. 
The tool is developed as a part of PAC-PAC, a project for promoting 
cultural and environmental heritage through videogames.

####Demo Video
<iframe width="560" height="340" src="https://www.youtube.com/embed/P13c1-kIt-g"></iframe>

####Paper
The paper was accepted as a demo at the the 7th International Symposium on End-User Development 
([IS-EUD 2019](https://sites.google.com/site/iseud2019/)). 

[Fulltext](2018/is-eud-demo-2019.pdf)

<a id="ai4fit"></a>
<hr>

###AI4Fit
*Federico Maria Cau, Mattia Samuel Mancosu*

####Abstract
This project is about an explainable intelligent interface supporting 
coaches in providing feedback to runners tracking their progress 
through a mobile application. The interface explicitly shows the 
confidence on the assigned ratings, it supports the impact analysis 
of the different recorded metrics and it allows controlling and reinforcing 
the assessment.

####Paper
The paper was accepted as a poster at the 24th annual meeting of the intelligent
user interface community meeting ([ACM IUI 2019](https://iui.acm.org/2019/)).

[Fulltext](2018/ai4fit-iui-paper.pdf)

<a id="mr2"></a>
<hr>

###MR2
*Carlo Cuccu, Vittoria Frau*

####Abstract
This project is about the design and implementation of a preliminary 
Mixed Reality interface for Microsoft Hololens, supporting medical 
records retrieval and navigation. The goal is to ease common activities 
in the dynamic clinical context, using facial recognition and multimodal 
commands for accessing medical records on the fly through a free-hand 
interaction.

####Demo Video
<iframe width="560" height="340" src="https://www.youtube.com/embed/s4U7GuC1a-o"></iframe>

####Paper
The paper was accepted as a demo at the he 8th ACM International Symposium on 
Pervasive Displays ([PerDis 2019](http://pervasivedisplays.org/2019/)) 

[Fulltext](2018/UIT_MR2.pdf)




